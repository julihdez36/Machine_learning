par(mfrow = c(1,2))
set.seed(42)
plot(g, vertex.size = 20, vertex.label.color = 'black')
corrplot::corrplot(corr = Y,method = 'color',addgrid.col = "gray",
cl.pos = "n", tl.col = "black")
par(mfrow = c(1,2))
set.seed(42)
plot(g, vertex.size = 20, vertex.label.color = 'black')
corrplot::corrplot(corr = Y,method = 'color',addgrid.col = "gray",
cl.pos = "n", tl.col = "black", col = 'orange')
corrplot::corrplot(corr = Y,method = 'color',addgrid.col = "gray",
cl.pos = "n", tl.col = "black")
dev.off()
windows()
vcount(g)
ecount(g)
# frecuencias de clanes
table(sapply(X = cliques(graph = g, min = 1, max = 10), FUN = length))
# clanes maximales
maximal.cliques(graph = g)
# clanes máximos
largest.cliques(graph = g)
# número clan
clique.number(graph = g)
data(karate)
?upgrade_graph()
karate
?upgrade_graph(karate)
upgrade_graph(karate)
as.matrix(get.adjacency(graph = karate, names = T))
as.matrix(get.adjacency(graph = karate, names = f))
as.matrix(get.adjacency(graph = karate, names = F))
Y <- as.matrix(get.adjacency(graph = karate, names = F))
vcount(karate)
ecount(karate)
windows()
set.seed(123)
plot(karate, layout = layout_with_dh, vertex.size = 10, vertex.frame.color = "black", vertex.label.color = "black", main = "")
# clanes máximos
largest.cliques(graph = karate)
# número clan
clique.number(graph = karate)
# densidad
ecount(karate)/(vcount(karate)*(vcount(karate)-1)/2)
edge_density(graph = karate)
mean(Y[lower.tri(Y, diag = F)])
library(igraph)
# Veamos un ejemplo sencillo
g <- graph(edges = c(1,2,1,3,1,4,1,5,2,3,2,4,2,5,3,4,3,5,4,5,6,7,6,8,7,8,9,10,1,6,2,9,7,9), directed = F)
get.adjacency(graph = g, names = F)
as.matrix(get.adjacency(graph = g, names = F))
get.adjacency(graph = g, names = F,sparse = T)
Y <- as.matrix(get.adjacency(graph = g, names = F))
source("C:/Users/Julian/Desktop/Cursos/Cursos Github/Complex_networks/7. Caracterización de la cohesión.R")
plot(g)
# Veamos un ejemplo sencillo
g <- graph(edges = c(1,2,1,3,1,4,1,5,2,3,2,4,2,5,3,4,3,5,4,5,6,7,6,8,7,8,9,10,1,6,2,9,7,9), directed = F)
windows()
plot(g)
par(mfrow = c(1,2), mar = c(4, 3, 3, 1))
set.seed(42)
plot(g, vertex.size = 20, vertex.color = 0, vertex.label.color = "black", edge.color = "blue4")
corrplot::corrplot(corr = Y, col.lim = c(0,1), method = "color", tl.col = "black", addgrid.col = "gray", cl.pos = "n")
Y
data(karate)
Y <- as.matrix(get.adjacency(graph = karate, names = F))
vcount(karate) # Orden 34
ecount(karate) # Tamaño 78
data(karate)
library(sand)
# clan?
# Crea subgrafo inducido que pasa por 6,7 y 8
c1 <- induced_subgraph(graph = g, vids = c(6,7,8))
# Comparamos las atistas con la función ecount que devuelve el número de
# aristas del subgrafo c1
ecount(c1) == choose(n = vcount(c1), k = 2)
# frecuencias de clanes
table(sapply(X = cliques(graph = g, min = 1, max = 10), FUN = length))
# clanes maximales
maximal.cliques(graph = g)
cliques(graph = g, min = 1, max = 10)
cliques(g)
length(cliques(g) )
table(cliques(g))
# Encontrar el número de cliques de cada tamaño
clique_size_counts(g, min_size = 1, max_size = 10)
table(sapply(cliques(g), length))
table(sapply(X = cliques(graph = g, min = 1, max = 10), FUN = length))
# clanes maximales
maximal.cliques(graph = g)
# clanes maximales
maximal.cliques(graph = g)
# clanes máximos
largest.cliques(graph = g)
# número clan
clique.number(graph = g)
data(karate)
Y <- as.matrix(get.adjacency(graph = karate, names = F))
vcount(karate) # Orden 34
ecount(karate) # Tamaño 78
windows()
set.seed(123)
plot(karate, layout = layout_with_dh, vertex.size = 10, vertex.frame.color = "black", vertex.label.color = "black", main = "")
# clanes máximos
largest.cliques(graph = karate)
# número clan
clique.number(graph = karate)
# Frecuencia de cliques
table(sapply(cliques(g), length))
cliques(karate)[sapply(cliques(karate), length) == 5]
# Frecuencia de cliques
table(sapply(cliques(karate), length))
cliques(karate)[sapply(cliques(karate), length) == 5] #ya sabemos que son 2
table(sapply(max_cliques(karate), length))
# clanes máximos
largest.cliques(graph = karate)
# clanes máximos
table(sapply(largest.cliques(graph = karate), length))
# número clan
clique.number(graph = karate)
# datos
data(yeast)
yeast <- upgrade_graph(yeast)
ecount(yeast) # tamaño
vcount(yeast) # orden
ecount(yeast) # tamaño
vcount(aidsblog) # Orden 146
ecount(aidsblog) # tamaño
is_directed(aidsblog) # dirigida
# visualización
set.seed(123)
par(mfrow = c(1,1), mar = c(4, 3, 3, 1))
plot(aidsblog, layout = layout_with_kk, vertex.label = NA, vertex.size = 5, vertex.frame.color = 1, edge.arrow.size = 0.5, main = "")
is_simple(aidsblog)
# censo de estados diádicos
#   mut   The number of pairs with mutual connections.
#   asym  The number of pairs with non-mutual connections.
#   null  The number of pairs with no connection between them.
dyad_census(aidsblog)
triad_census(aidsblog)
aidsblog <- simplify(aidsblog)
dyad_census(aidsblog)
#   mut   The number of pairs with mutual connections.
#   asym  The number of pairs with non-mutual connections.
#   null  The number of pairs with no connection between them.
dyad_census(aidsblog)
# También podemos ver el censo de estados triadicos
triad_census(aidsblog)
graph.density(karate)
# densidad: usamos la f'romula combinatoria para grafos no dirigidos
# N*(N-1)/2, N = no. vertices
ecount(karate)/(vcount(karate)*(vcount(karate)-1)/2)
edge_density(graph = karate)
mean(Y[lower.tri(Y, diag = F)])
mean(Y[upper.tri(Y, diag = F)])
# ego networks
g_1  <- induced_subgraph(graph = karate, vids = neighborhood(graph = karate, order = 1, nodes = 1) [[1]])
g_34 <- induced_subgraph(graph = karate, vids = neighborhood(graph = karate, order = 1, nodes = 34)[[1]])
# densidades
edge_density(graph = g_1)
edge_density(graph = g_34)
edge_density(graph = karate)
# visualización
set.seed(123)
plot(h, vertex.size = 20, vertex.color = 0, vertex.label.color = "black", edge.color = "blue4")
h <- graph(edges = c(1,2,1,3,2,3,1,4), directed = F)
# visualización
set.seed(123)
plot(h, vertex.size = 20, vertex.color = 0, vertex.label.color = "black", edge.color = "blue4")
# visualización
windows()
set.seed(123)
plot(h, vertex.size = 20, vertex.color = 0, vertex.label.color = "black", edge.color = "blue4")
# número de triángulos por vértice
count_triangles(graph = h)
# vértices que son parte de un triángulo
triangles(graph = h)
# conteos de estados triádicos
(mot <- motifs(graph = h, size = 3))
# transitividad
3*mot[4]/(mot[3] + 3*mot[4])
transitivity(graph = h, type = "global")
edge_density(graph = karate)
# reciprocidad (aristas)
reciprocity(aidsblog, mode = "default")
# reciprocidad (díadas)
reciprocity(aidsblog, mode = "ratio")
# red conectada?
is_connected(yeast)
# componentes
componentes <- decompose(yeast)
length(componentes)
table(sapply(X = componentes, FUN = vcount))
# red conectada?
is_connected(yeast)
# componentes
componentes <- decompose(yeast)
length(componentes)
decompose(yeast)
length(componentes)
table(sapply(X = componentes, FUN = vcount))
# tamaño de la componte gigante
max(sapply(X = componentes, FUN = vcount))
max(sapply(X = componentes, FUN = vcount))/vcount(yeast)
# componente gigante
yeast_gc <- decompose(yeast)[[1]]
# vértice-conectividad
vertex_connectivity(yeast_gc)
# vértice-conectividad
vertex_connectivity(yeast_gc)
mean_distance(yeast_gc)
transitivity(yeast_gc)
diameter(yeast_gc)
# vértice-conectividad
vertex_connectivity(yeast_gc)
# arista-conectividad
edge_connectivity(yeast_gc)
# vértice-conectividad
vertex_connectivity(yeast_gc)
# puntos de articulación
yeast_cv <- articulation_points(yeast_gc)
length(yeast_cv)
length(yeast_cv)/vcount(yeast_gc)
library(igraph)
library(igraphdata)
data("yeast")
ecount(yeast)
vcount(yeast) # orden
# clases
table(V(yeast)$Class)
# Quiero validar si todos los nodos están clasificados
sum(table(V(yeast)$Class))
# validemos si hay NAs?
table(is.na(V(yeast)$Class))
# clase P: desempeñan un papel en la síntesis de proteínas
v.types <- (V(yeast)$Class == "P") + 1
v.types[is.na(v.types)] <- 1
table(v.types)
# asortatividad nominal
assortativity_nominal(graph = yeast, types = v.types, directed = F)
# asortatividad grado
assortativity_degree(yeast)
# datos
data(karate)
karate <- upgrade_graph(karate)
# la representación de datos internos a veces cambia entre versiones
Y <- as.matrix(get.adjacency(graph = karate, names = F))
# orden
vcount(karate)
# tamaño
ecount(karate)
# visualización
windows()
par(mfrow = c(1,1), mar = c(4, 3, 3, 1))
set.seed(123)
plot(karate, layout = layout_with_dh, vertex.size = 10, vertex.frame.color = "black", vertex.label.color = "black", main = "")
# clase
v.types <- V(karate)$Faction
# asortatividad nominal
assortativity_nominal(graph = karate, types = v.types, directed = F)
# asortatividad grado
assortativity_degree(karate)
library(sand)
# datos
lazega <- graph_from_data_frame(d = elist.lazega, directed = "F", vertices = v.attr.lazega)
V(lazega)$label <- sub("V", "", V(lazega)$name)
vcount(lazega) # orden
ecount(lazega) # tamaño
# asortatividad nominal a nivel de la sede de la oficina
assortativity(graph = lazega, types1 = V(lazega)$Office)
assortativity(graph = lazega, types1 = V(lazega)$Practice)
assortativity(graph = lazega, types1 = V(lazega)$School)
assortativity(graph = lazega, types1 = V(lazega)$Years)
assortativity(graph = lazega, types1 = degree(lazega))
assortativity_degree(graph = lazega, directed = F)
knitr::opts_chunk$set(echo = TRUE)
supressMessages(suppressWarnings(library(igraph)))
suppressMessages(suppressWarnings(library(igraph)))
suppressMessages(suppressWarnings(library(sand)))
data(fblog)
(n <- vcount(fblog)) #192
(e <- ecount(fblog)) #1431
A <- as.matrix(as_adjacency_matrix(fblog))
suppressMessages(suppressWarnings(library(igraph)))
suppressMessages(suppressWarnings(library(sand)))
data(fblog)
(n <- vcount(fblog)) #192
(e <- ecount(fblog)) #1431
A <- as.matrix(as_adjacency_matrix(fblog))
colnames(A) <- rownames(A) <- rep("",n)
suppressMessages(suppressWarnings(library(igraph)))
suppressMessages(suppressWarnings(library(sand)))
library(dplyr)
data(fblog)
(n <- vcount(fblog)) #192
(e <- ecount(fblog)) #1431
A <- as.matrix(as_adjacency_matrix(fblog))
colnames(A) <- rownames(A) <- rep("",n)
suppressMessages(suppressWarnings(library(igraph)))
suppressMessages(suppressWarnings(library(sand)))
suppressMessages(suppressWarnings(library(dplyr)))
data(fblog)
(n <- vcount(fblog)) #192
(e <- ecount(fblog)) #1431
A <- as.matrix(as_adjacency_matrix(fblog))
colnames(A) <- rownames(A) <- rep("",n)
ncn <- numeric()
for(i in (1:(n-1))){
.ni <- ego(fblog, 1, i)
.nj <- ego(fblog, 1, (i+1):n)
.nbhd.ij <- mapply(intersect, .ni, .nj, SIMPLIFY=FALSE)
.temp <- unlist(lapply(.nbhd.ij, length)) -2*A[i, (i+1):n]
ncn <- c(ncn, .temp)
}
ncn %>% head(3)
pred_ncn <- prediction(ncn, Avec)
ncn <- numeric()
for(i in (1:(n-1))){
.ni <- ego(fblog, 1, i)
.nj <- ego(fblog, 1, (i+1):n)
.nbhd.ij <- mapply(intersect, .ni, .nj, SIMPLIFY=FALSE)
.temp <- unlist(lapply(.nbhd.ij, length)) -2*A[i, (i+1):n]
ncn <- c(ncn, .temp)
}
length(ncn)
library(vioplot)
library(vioplot)
install.packages("vioplot")
install.packages("ROCR")
library(vioplot)
library(ROCR)
pred_ncn <- prediction(ncn, Avec)
library(igraph)
library(sand)
g.RegDB <- graph_from_adjacency_matrix(adjmatrix=regDB.adj, mode = "undirected")
plot(g.RegDB, vertex.label=NA, vertex.size =7.5, vertex.frame.color = "black")
title(main = "Red E.Coli")
windows()
plot(g.RegDB, vertex.label=NA, vertex.size =7.5, vertex.frame.color = "black")
title(main = "Red E.Coli")
vcount(g.RegDB)
ecount(g.RegDB)
data(Ecoli.data)
r <- cor(Ecoli.expr)
z <- 0.5 * log((1 + r) / (1 - r))
z.vec <- z[upper.tri(z)]
n <- dim(Ecoli.expr)[1]
corr.pvals <-2 * pnorm(abs(z.vec), 0, sqrt(1 / (n - 3)), lower.tail = FALSE)
length(corr.pvals)
corr.pvals.adj <- p.adjust(corr.pvals, "BH")
table(corr.pvals.adj <0.05) #luego del ajuste
car::qqPlot(z.vec)
shapiro.test(x = sample(x = z.vec, size = 5000, replace = F))
library(fdrtool)
install.packages("fdrtool")
library(fdrtool)
library(fdrtool) # Control de tasas de falsos descubrimientos
#calculo de los valores p, de nuevo
r.vec <- r[upper.tri(r)]
fdr <-fdrtool(x = r.vec,statistic = "correlation",plot = F,verbose = F)
length(fdr$qval)
head(fdr$qval) # arrojan no significativos
table(fdr$qval <0.05)
#correlaciones agregadas y obteniendo el max
m <- 1
pcorr.pvals <- matrix(0, N, N)
for (i in 1:N) {
for (j in 1:N) {
rowi <- r[i,-c(i, j)]
rowj <- r[j,-c(i, j)]
tmp <- (r[i, j] - rowi * rowj) / sqrt((1 - rowi^2) * (1 - rowj^2)) #correlaciones parciales
tmp.zvals <-(0.5) * log((1 + tmp) / (1 - tmp)) #estadístico de prueba
tmp.pvals <-2 * pnorm(abs(tmp.zvals),mean = 0,sd = 1 / sqrt(n - m - 3),lower.tail = FALSE)
pcorr.pvals[i, j] <-max(tmp.pvals)
}
}
#correlaciones agregadas y obteniendo el max
m <- 1
pcorr.pvals <- matrix(0, N, N)
for (i in 1:N) {
for (j in 1:N) {
rowi <- r[i,-c(i, j)]
rowj <- r[j,-c(i, j)]
tmp <- (r[i, j] - rowi * rowj) / sqrt((1 - rowi^2) * (1 - rowj^2)) #correlaciones parciales
tmp.zvals <-(0.5) * log((1 + tmp) / (1 - tmp)) #estadístico de prueba
tmp.pvals <-2 * pnorm(abs(tmp.zvals),mean = 0,sd = 1 / sqrt(n - m - 3),lower.tail = FALSE)
pcorr.pvals[i, j] <-max(tmp.pvals)
}
}
#Tamaño de la muestra
n <- nrow(Ecoli.expr)
n
#n de vertices
N <- ncol(Ecoli.expr)
N
#correlaciones agregadas y obteniendo el max
m <- 1
pcorr.pvals <- matrix(0, N, N)
for (i in 1:N) {
for (j in 1:N) {
rowi <- r[i,-c(i, j)]
rowj <- r[j,-c(i, j)]
tmp <- (r[i, j] - rowi * rowj) / sqrt((1 - rowi^2) * (1 - rowj^2)) #correlaciones parciales
tmp.zvals <-(0.5) * log((1 + tmp) / (1 - tmp)) #estadístico de prueba
tmp.pvals <-2 * pnorm(abs(tmp.zvals),mean = 0,sd = 1 / sqrt(n - m - 3),lower.tail = FALSE)
pcorr.pvals[i, j] <-max(tmp.pvals)
}
}
pcorr.pvals.vec <- pcorr.pvals[lower.tri(pcorr.pvals)]
pcorr.pvals.adj <- p.adjust(pcorr.pvals.vec, "BH")
table(pcorr.edges)
pcorr.edges <- (pcorr.pvals.adj < 0.05)
table(pcorr.edges)
#correlaciones agregadas y obteniendo el max
m <- 1
pcorr.pvals <- matrix(0, N, N)
for (i in 1:N) {
for (j in 1:N) {
rowi <- r[i,-c(i, j)]
rowj <- r[j,-c(i, j)]
tmp <- (r[i, j] - rowi * rowj) / sqrt((1 - rowi^2) * (1 - rowj^2)) #correlaciones parciales
tmp.zvals <-(0.5) * log((1 + tmp) / (1 - tmp)) #estadístico de prueba
tmp.pvals <-2 * pnorm(abs(tmp.zvals),mean = 0,sd = 1 / sqrt(n - m - 3),lower.tail = FALSE)
pcorr.pvals[i, j] <-max(tmp.pvals)
}
}
pcorr.pvals.vec <- pcorr.pvals[lower.tri(pcorr.pvals)]
pcorr.pvals.adj <- p.adjust(pcorr.pvals.vec, "BH")
pcorr.edges <- (pcorr.pvals.adj < 0.05)
table(pcorr.edges)
?fdrtool(x = r.vec,statistic = "correlation",plot = F,verbose = F)
library(httr)
library(tidyverse)
library(glue)
library(devtools)
install.packages("devtools")
library(devtools)
install_github("mikeasilva/blsAPI")
## Single Series request
response <- blsAPI('LAUCN040010000000005')
## Single Series request
payload <- list('seriesid'=c('LAUCN040010000000005','LAUCN040010000000006'))
View(payload)
response <- blsAPI(payload)
payload[[1]]
as.data.frame(payload)
estudiantes <- c("mujer", "mujer", "mujer", "mujer", "hombre",
"hombre", "hombre", "hombre", "hombre", "hombre")
sample(estudiantes, 1)
estudiantes <- rep(x = rep(c('Mujer','Hombre'), times = c(4,6)))
<- rep(x = rep(c('Mujer','Hombre'), times = c(4,6)))
estudiantes
?replicate(n = 100,expr = )
?replicate(n = 100,expr = sample(estudiantes, 1))
replicate(n = 100,expr = sample(estudiantes, 1))
simulacion <- NULL
for (i in 1:100) {
simulacion <- c(simulacion, sample(estudiantes,1))
}
simulacion
sample(x = estudiantes,size = 100)
sample(x = estudiantes,size = 100)
sample(x = estudiantes,size = 100,replace = T)
simulacion <- c()
for (i in 1:100) {
simulacion <- c(simulacion, sample(estudiantes,1))
}
simulacion
table(simulacion)
prop.table(table(simulacion))
simulacion_2 <- sample(x = estudiantes,size = 1000,replace = T)
prop.table(table(simulacion_2))
numeros <- c("As", "Dos", "Tres", "Cuatro", "Cinco", "Seis", "Siete",
"Ocho", "Nueve", "Diez", "Jack", "Reina", "Rey")
palos <- c("de Corazones", "de Diamantes", "de Picas", "de Tréboles")
expand.grid(numero = numeros, palo = palos)
# Creamos la combinatoria de cartas
combinatoria <- expand.grid(numero = numeros, palo = palos)
# Concatenamos vectores para tener nuestra combinación final
paste(combinatoria$numero, combinatoria$palo)
# Concatenamos vectores para tener nuestra combinación final
baraja <- paste(combinatoria$numero, combinatoria$palo)
mean(baraja == 'Rey de Diamantes')
paste("Reina", palos)
mean(paste("Reina", palos) %in% baraja )
mean(baraja %in% paste("Reina", palos))
dado <- 1:6
# Para empezar a usarlo cargamos la librería gtools
library(gtools)
competitors <- c("Jenny", "Freddy", "Yasan", "Iver", "Pamela", "Alexandra",
"Bladimir", "Enrique", "Karen", "Christiam")
# Instalar y cargar el paquete blsAPI
install.packages("blsAPI")
library(blsAPI)
# URL para obtener la lista de series de datos del IPC
url_series <- "https://download.bls.gov/pub/time.series/cu/cu.series"
# Descargar el archivo y leerlo en R
download.file(url_series, destfile = "cu_series.txt")
series_data <- read.delim("cu_series.txt", sep = "\t", header = TRUE, stringsAsFactors = FALSE)
# Mostrar las primeras filas del data frame
head(series_data)
tinytex::reinstall_tinytex(repository = "illinois")
fdr <-
?fdrtool(r.vec , statistic="correlation")
# fdr <-
?fdrtool(r.vec , statistic="correlation")
library(fdrtool)
?fdrtool()
x <- rnorm(100)
hist(x)
getwd()
setwd('C:\\Users\\Julian\\Desktop\\Cursos\\Cursos Github\\Machine_learning\\Text mining')
